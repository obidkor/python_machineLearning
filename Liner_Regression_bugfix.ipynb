{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8035407237785419, 0.5345224838248489], [0.9788586998756785, -0.066815310478106], [-1.6509109415813705, -1.6703827619526523], [-0.7743210610956874, -0.6681531047810609], [-0.336026120852846, 0.3340765523905306], [0.9788586998756785, 1.5367521409964404]]\n",
      "[[-0.949639037192824, -0.5478855459204699], [0.8911997118271102, -0.066815310478106]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[178,75],[180,60],[150,20],[160,45],[165,70],[180,100]]\n",
    "y_data = [[1],[1],[0],[0],[1],[1]]\n",
    "#새로운 데이터\n",
    "new_data = [[158,48],[179,60]]\n",
    "\n",
    "#데이터를 값의 간격이 너무커서 nan이 뜸;;;;;\n",
    "#계산하기 좋게 standardization 해야함 ㅎㅎ;\n",
    "#x-new = x-평균/표준편차로 다시선어헤야함;\n",
    "#키의 평균 표준편차 / 몸무게 평균 표준편차로 다시 해야함;\n",
    "#numpy 라이브러리 이용\n",
    "\n",
    "new_x = np.array(x_data)\n",
    "h_ave = np.mean(new_x[:,0])\n",
    "w_ave = np.mean(new_x[:,1])\n",
    "h_std = np.std(new_x[:,0])\n",
    "w_std = np.std(new_x[:,1])\n",
    "\n",
    "index = 0\n",
    "#standardization!(요소값-평균)/표준편차\n",
    "for i in x_data:\n",
    "    x_data[index][0]= (x_data[index][0]-h_ave)/h_std\n",
    "    x_data[index][1]= (x_data[index][1]-w_ave)/w_std\n",
    "    index = index+1\n",
    "index=0\n",
    "#새로운 데이터도 정규화해줌!(기존의 평균과 / 표준편차로)\n",
    "for i in new_data:\n",
    "    new_data[index][0]= (new_data[index][0]-h_ave)/h_std\n",
    "    new_data[index][1]= (new_data[index][1]-w_ave)/w_std\n",
    "    index = index+1    \n",
    "print(x_data)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder fro a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "#새로운데이터가 들어가플레이스 홀더(사실 필요 없음)\n",
    "N = tf.placeholder(tf.float32, shape=[None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([2,1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis using sigmoid\n",
    "#X를 통해 hypothesis를 만듦..(시그모이드함수로 결과값을 구함)\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost/loss fuction\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))#에러\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)#에러를 경사감소법으로 최소화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy computation\n",
    "#True if hypothesis >0.5 else false\n",
    "predicted = tf.cast(hypothesis >0.5, dtype=tf.float32)#hypothesis(결과값)이 0.5 이상이면 \n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.6027744 [[-1.6652526]\n",
      " [-1.220839 ]] [-0.3742016]\n",
      "5000 0.05595997 [[2.1588774]\n",
      " [2.7446942]] [1.531515]\n",
      "10000 0.032165106 [[2.638408]\n",
      " [3.618266]] [1.937279]\n",
      "\n",
      "Hypothesis :  [[9.9750602e-01]\n",
      " [9.8632145e-01]\n",
      " [2.1123886e-04]\n",
      " [7.4244142e-02]\n",
      " [9.0546536e-01]\n",
      " [9.9995816e-01]] \n",
      "Correct (Y):  [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy :  1.0\n",
      "\n",
      "Hypothesis :  [[0.07238271]\n",
      " [0.98282325]] \n",
      "Correct (Y):  [[0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#Lanuch graph\n",
    "with tf.Session() as sess:\n",
    "    #Initiation tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cost_val, W_val, B_val, _ = sess.run([cost,W,b,train],\\\n",
    "                                             feed_dict={X:x_data,Y:y_data})\n",
    "        if step % 5000 ==0:\n",
    "            print(step,cost_val,W_val,B_val)\n",
    "    #accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],feed_dict={X:x_data,Y:y_data})\n",
    "    print (\"\\nHypothesis : \",h,\"\\nCorrect (Y): \",c,\"\\nAccuracy : \",a)\n",
    "    #새로운 데이터를 넣으려면 \n",
    "    h, c = sess.run([hypothesis, predicted],feed_dict={X:new_data})\n",
    "    print (\"\\nHypothesis : \",h,\"\\nCorrect (Y): \",c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
